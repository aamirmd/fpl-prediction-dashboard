{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPtLutNrugUg2VfRAR6C+TK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"rAzrLJpeSwPV"},"outputs":[],"source":["import pandas as pd\n","import os\n","import numpy as np"]},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","\n","# 1. Mounting Google Drive: This allows Colab to access files in your Google Drive\n","drive.mount('/content/drive')\n","basedir = \"/content/drive/MyDrive/cs6365/\""],"metadata":{"id":"qpRg1ppWT6Qj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df21 = pd.read_csv('/content/drive/MyDrive/cs6365/merged_gw_2021_22.csv')\n","df22 = pd.read_csv('/content/drive/MyDrive/cs6365/merged_gw_2022_23.csv')\n","df23 = pd.read_csv('/content/drive/MyDrive/cs6365/merged_gw_2023_24.csv')"],"metadata":{"id":"BqzvjiPaTqvq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df23.columns"],"metadata":{"id":"yj41PeSEUqeo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Columns to drop: Name, team, position, element, fixture, kickoff time (tbd), opponent team, round, transfer_balance\n","\n","\n","Target data: total_points of next gameweek\n","\n","preprocessing steps:\n","- Change was_home to 0/1"],"metadata":{"id":"dKe5zQgoXTKC"}},{"cell_type":"markdown","source":["# Quick and dirty baseline model"],"metadata":{"id":"R0vjatE5Vb1k"}},{"cell_type":"code","source":["# Dropping unnecessary columns\n","train_df = df21.drop([\"name\", \"team\", \"position\", \"fixture\", \"kickoff_time\", \"opponent_team\", \"round\", \"transfers_balance\"], axis=1)\n","\n","# Create a column for ground truth\n","ground_truth = df21.loc[:, [\"element\", \"total_points\", \"GW\"]]\n","\n","# total points for GW 2 becomes the ground truth for GW 1\n","ground_truth['GW'] -= 1\n","ground_truth = ground_truth.rename(columns={\"total_points\":\"y\"})\n","\n","# inner join with train df\n","train_df = train_df.merge(ground_truth, how=\"inner\", on=[\"element\", \"GW\"])\n","\n","# Dropping 'element' and 'gw' columns as they are no longer needed\n","train_df = train_df.drop([\"element\", \"GW\"], axis=1)\n","train_df"],"metadata":{"id":"N6LZLx3IVpb7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Pre-processing\n","train_df = train_df.astype(np.float32)\n","train_df"],"metadata":{"id":"EdxEto1PUDkc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train model\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader"],"metadata":{"id":"IUDJbDcabjeu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class FplDataset(Dataset):\n","    def __init__(self, inputs, targets):\n","        self.inputs = inputs\n","        self.targets = targets\n","\n","    def __len__(self):\n","        return len(self.inputs)\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.inputs.loc[idx], dtype=torch.float32), torch.tensor(self.targets.loc[idx], dtype=torch.float32)\n","\n","# Convert data to PyTorch Dataset and DataLoader\n","inputs = train_df.drop('y', axis=1)\n","num_features = inputs.shape[1]\n","targets = train_df.loc[:,\"y\"]\n","dataset = FplDataset(inputs, targets)\n","dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"],"metadata":{"id":"-ccawROucQfq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define a simple model\n","class SimpleModel(nn.Module):\n","    def __init__(self, num_features):\n","        super(SimpleModel, self).__init__()\n","        self.layer1 = nn.Linear(num_features, 64)  # 64 output units\n","        self.layer2 = nn.Linear(64, 1)   # 64 input units, 1 output value\n","\n","    def forward(self, x):\n","        x = torch.relu(self.layer1(x))  # Apply ReLU activation after first layer\n","        x = self.layer2(x)              # Output layer\n","        return x\n","\n","# Initialize the model, loss function, and optimizer\n","model = SimpleModel(num_features)\n","criterion = nn.MSELoss()  # Mean Squared Error loss for regression task\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"],"metadata":{"id":"YmTcQwDcdk9f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training loop\n","num_epochs = 10\n","for epoch in range(num_epochs):\n","    model.train()  # Set model to training mode\n","    running_loss = 0.0\n","\n","    for inputs_batch, targets_batch in dataloader:\n","        # Forward pass\n","        outputs = model(inputs_batch)\n","        loss = criterion(outputs, targets_batch)\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","    avg_loss = running_loss / len(dataloader)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"],"metadata":{"id":"z3cyv4R3eJrs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save the trained model\n","torch.save(model.state_dict(), 'drive/MyDrive/cs6365/baseline.pth')"],"metadata":{"id":"lhbgrZ_Be-Tw"},"execution_count":null,"outputs":[]}]}